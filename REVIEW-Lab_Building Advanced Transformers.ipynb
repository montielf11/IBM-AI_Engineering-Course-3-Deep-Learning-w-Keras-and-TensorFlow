{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Understand the core components of a Transformer architecture.\n",
    "- Implement a multi-head self-attention mechanism from scratch.\n",
    "- Train and evaluate a Transformer for time series prediction.\n",
    "- Handle preprocessing and scaling for time series data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Transformer?\n",
    "\n",
    "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
    "\n",
    "### Key Components:\n",
    "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
    "- **Positional Encoding:** Injects information about the position of input tokens.\n",
    "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
    "- **Feedforward Layers:** Process the attended information.\n",
    "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
    "\n",
    "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
    "\n",
    "**Next:** You will implement parts of this architecture step-by-step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting numpy>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pillow (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.74.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.14.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.2-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (408 kB)\n",
      "Downloading pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, pyarrow, protobuf, pillow, optree, opt_einsum, numpy, mdurl, markdown, grpcio, google_pasta, gast, astunparse, absl-py, tensorboard, ml_dtypes, markdown-it-py, h5py, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.74.0 h5py-3.14.0 keras-3.11.2 libclang-18.1.1 markdown-3.8.2 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 numpy-2.3.2 opt_einsum-3.4.0 optree-0.17.0 pillow-11.3.0 protobuf-6.31.1 pyarrow-21.0.0 rich-14.1.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m141.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.3.2)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m138.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.1 scipy-1.16.1 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (107 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m143.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m122.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.0 kiwisolver-1.4.9 matplotlib-3.10.5 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 13:56:33.520931: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-14 13:56:33.521447: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-14 13:56:33.590620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-08-14 13:56:35.382812: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-14 13:56:35.383919: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-14 14:41:58.242110: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - loss: 3.9982  \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 1s/step - loss: 0.2027 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - loss: 0.1879 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - loss: 0.2410\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 3s/step - loss: 0.1602\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - loss: 0.1599\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 3s/step - loss: 0.1442\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.1203 \n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.1441 \n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - loss: 0.0972 \n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0804 \n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0841 \n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0793 \n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0593 \n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0705 \n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0463 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0360 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - loss: 0.0339 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0271 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.0367 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x771de85d5340>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 328ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Prepare true values for comparison\n",
    "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(true_values, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - loss: 2.8763  \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.8890 \n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - loss: 0.4003 \n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.1534 \n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 1s/step - loss: 0.0722 \n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: 0.0499\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - loss: 0.0466\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - loss: 0.0301\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2s/step - loss: 0.0219\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - loss: 0.0221\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - loss: 0.0202\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - loss: 0.0163\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - loss: 0.0160\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - loss: 0.0130\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - loss: 0.0147\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 1s/step - loss: 0.0117 \n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.0128 \n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.0102 \n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.0112 \n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - loss: 0.0151 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 332ms/step - loss: 0.0071    \n",
      "Test loss: 0.007109411526471376\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "dropout = Dropout(0.5)(flatten) \n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "# Build the model \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Train the model \n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "# Evaluate the model \n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "dropout = Dropout(0.5)(flatten) \n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "# Build the model \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Train the model \n",
    "model.fit(X, Y, epochs=20, batch_size=16) \n",
    "\n",
    "# Evaluate the model \n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - loss: 1.5803  \n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.5864\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.2936 \n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.1148 \n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0496\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0290 \n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0218\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0179\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0153 \n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0126\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0119 \n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0129\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0128 \n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0081 \n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0092 \n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0080\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0069\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0091\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 2s/step - loss: 0.0084 \n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 2s/step - loss: 0.0091 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 329ms/step - loss: 0.0015\n",
      "Test loss: 0.0014856017660349607\n"
     ]
    }
   ],
   "source": [
    "## Write your code here.\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "dropout = Dropout(0.5)(flatten) \n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "# Build the model \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Train the model \n",
    "model.fit(X, Y, epochs=20, batch_size=64) \n",
    "\n",
    "# Evaluate the model \n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here.\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
